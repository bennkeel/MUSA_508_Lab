---
title: "Marketing Campaign for a Housing Subsidy"
author: "Ben Keel"
date: "2022-11-04"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

# Who Would Take a Subsidy?





# Important Features

## Data Collecting

First step is to import the data source and libraries to be used for analysis.

```{r setup, include=FALSE, warning = FALSE, message = FALSE}

library(tidyverse)
library(kableExtra)
library(caret)
library(knitr) 
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(broom)
library(stargazer)
library(ggplot2)
library(gridExtra)

knitr::opts_chunk$set(echo = TRUE)

source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

options(scipen = '999')

palette5 <- c("#981FAC","#CB0F8B","#FF006A","#FE4C35","#FE9900")
palette4 <- c("#981FAC","#FF006A","#FE4C35","#FE9900")
palette2 <- c("#981FAC","#FF006A")

g <- glimpse

subsidy <- read.csv("D:\\MUSAFall\\MUSA_508\\Public-Policy-Analytics-Landing-master\\DATA\\Chapter6\\housingSubsidy.csv")

subsidy$y <- factor(subsidy$y, levels = c("yes", "no"))

```

## Current Features

Below are collections of graphs to be used for feature selection when building a more effective model. Our data has results from previous campaigns that will enable a forecast of future participation in the housing subsidy. A "yes" here means that the person chose to participate, and may or may not have completed the application completely and received a subsidy. 

```{r DV Continuous likelihood, warning = FALSE, message = FALSE}

subsidy %>%
  dplyr::select(y, age, spent_on_repairs, inflation_rate, unemploy_rate, previous, campaign) %>%
  gather(Variable, value, -y) %>%
    ggplot(aes(y, value, fill=y)) + 
      geom_bar(position = "dodge", stat = "summary", fun = "mean") + 
      facet_wrap(~Variable, scales = "free") +
      scale_fill_manual(values = palette2) +
      labs(x="Participated?", y="Value", 
           title = "Feature associations with the likelihood of Participation",
           subtitle = "(continous outcomes)") +
      theme(legend.position = "none")


```

Age appears to have little bearing, at least when displayed in this form, same with the amount that a household spent on repairs previously. More useful indicators seem to be The current unemployment rate and whether or not the household had been involved with a previous campaign. 

However, plotting age across a continuous stream illustrates some different patterns of participation at different ranges of age. Similar with the "spent_on_repairs" vector, these features could be adjusted for more relevancy in the model. Other fields remain difficult to parse, like the consumer confidence and price indices. 
```{r DV Continuous Distribution}

subsidy %>%
    dplyr::select(y, age, cons.conf.idx, cons.price.idx, unemploy_rate, inflation_rate, spent_on_repairs) %>%
    gather(Variable, value, -y) %>%
    ggplot() + 
    geom_density(aes(value, color=y), fill = "transparent") + 
    facet_wrap(~Variable, scales = "free") +
    scale_fill_manual(values = palette2) +
    labs(title = "Feature Distributions of Participation",
         subtitle = "Continous Outcomes",
         legend.title= "Result")


```

The bar charts below show categorical variables from the data set, both in the citizens's rates of participation and the raw counts for each category. When trying to find the right indicators of whether someone participated in the program or not, certain categories appear to be very relevant when their ratio of yes's to no's. However, double checking the raw counts reveal that some of the categories with the highest ratio of yes's to no's may not have a relatively sufficient number to compare to other categories. The job numbers, with its large variation between the raw counts of citizens marketed to, are a good example here. If their rate may warped by the low count of citizens in that cross-tab, then it serves as a less effective indicator than we may hope for, and we can ignore it when engineering features.

```{r DV Categorical Features: Personal Info, warning = FALSE, message = FALSE}


#Rate Graphs
subsidy %>%
    dplyr::select(y, job, marital, education, mortgage, taxbill_in_phl) %>%
    gather(Variable, value, -y) %>%
    count(Variable, value, y) %>%
    group_by(Variable) %>%
      mutate(rate = lag(n)/n)%>%
    filter(y == "no" & value != "illiterate")%>%
      ggplot(., aes(value, rate)) +   
        geom_bar(position = "dodge", stat="identity") +
        facet_wrap(~Variable, scales="free") +
        labs(x="Category", y="Ratio of 'Yes' to 'No'",
             title = "Feature Associations with the Likelihood of Participation",
             subtitle = "Categorical features") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))


#Quantity Graphs
subsidy %>%
    dplyr::select(y, job, marital, education, taxLien, mortgage, taxbill_in_phl) %>%
    gather(Variable, value, -y) %>%
    count(Variable, value, y) %>%
      ggplot(., aes(value, n, fill = y)) +   
        geom_bar(position = "dodge", stat="identity") +
        facet_wrap(~Variable, scales="free") +
        scale_fill_manual(values = palette2) +
        labs(x="Category", y="Value",
             title = "Feature Associations with Counts of Participation",
             subtitle = "Categorical features") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

The same conclusion can be drawn from the "months" data illustrated below. December has a small amount of data recorded, yet it is up with March as one of the best times to contact someone to increase likelihood of participation. These differences are helpful when changing rates. 

```{r DV Categorical Features: Campaign Contact Info, warning = FALSE, message = FALSE}

#Rate Graphs
subsidy %>%
    dplyr::select(y, contact, pdays, month, day_of_week, poutcome) %>%
    gather(Variable, value, -y) %>%
    count(Variable, value, y)%>%
  mutate(rate = lag(n)/n)%>%
    filter(y=="no")%>%
      ggplot(., aes(value, rate)) +   
        geom_bar(position = "dodge", stat="identity") +
        facet_wrap(~Variable, scales="free") +
        labs(x="Category", y="Ratio of 'Yes' to 'No'",
             title = "Feature associations with the likelihood of Participation",
             subtitle = "Categorical features") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))

#Quantity Graphs
subsidy %>%
    dplyr::select(y, contact, month, day_of_week, poutcome) %>%
    gather(Variable, value, -y) %>%
    count(Variable, value, y) %>%
      ggplot(., aes(value, n, fill = y)) +   
        geom_bar(position = "dodge", stat="identity") +
        facet_wrap(~Variable, scales="free") +
        scale_fill_manual(values = palette2) +
        labs(x="Category", y="Value",
             title = "Feature Associations with Counts of Participation",
             subtitle = "Categorical features") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

## Data Split + Modeling

To start with the modeling, we split the base data set into 65% and 35% parts, then throw every variable into the model to get a baseline read on how the logistic regression will interpret this data.

```{r Data Partition and "Kitchen Sink" Regression, warning = FALSE, message = FALSE}

set.seed(999)
trainIndex <- createDataPartition(subsidy$y, p = .65,
                                  list = FALSE,
                                  times = 1)
subsidyTrain <- subsidy[ trainIndex,]
subsidyTest  <- subsidy[-trainIndex,]

subsidyModel <- glm(y_numeric ~ .,
                  data=subsidyTrain %>% 
                    dplyr::select(-y),
                  family="binomial" (link="logit"))

summary(subsidyModel)

```

Many of the features do not appear to be significant, signaling that we can do some cleaning of the features to avoid risking multi-collinearity, overlapping the effects that different features have on the prediction.

Looking at the McFadden R-Squared Value below, one would hope to move this value closer to 1 when engineering more relevant features. 

```{r Standard Reg McFadden R-squared, warning = FALSE, message = FALSE}
regSubsidySummary <- 
  tidy(pR2(subsidyModel))%>%
  mutate(Regression = "Kitchen Sink")

regSubsidySummary%>%
  filter(names=="McFadden")%>%
  rename(Value = x,
         Measure = names)%>%
    kable(
    caption = "<strong></strong>",
    escape= FALSE,
    format="html",
    row.names = FALSE,
    align="l")%>%
  kable_styling()

```

## New Features

Four new features were added or attempted for this sake, to increase the predictive relevancy of logistic regression and account for variance with tangible terms. First, the "spent_on_repairs" term was one of the terms with a lower p-value and a large gap at the tail end of its data. By focusing in on the variance above 4800, it hopefully makes the value better at forecasting participation chances. 

Age showed a similar variance in patterns across space, so I categorized it based on the areas with the largest or smallest gaps between yes and no in the continuous variable plots.

Employed numbers, grouping students, unemployed citizens, and retirees in a group, seemed to create a useful difference between categories.

Months was a variable with high significance, per the regression summary, but the many categories left many individual variables with similar high p-values and low significance. Grouping these months by their relative activity and high ratio of yes's to no's focused the variable into more relevant terms or "high", "med", and "low" collection volume and relative performance.

```{r Feature Engineering, warning = FALSE, message = FALSE}
#Engineer new features
##Summarize job as currently working vs not working. 
subsidyRevised <- 
  subsidy%>%
  mutate(Repairs_4800up = spent_on_repairs-4800,
         Employed = ifelse(job == "unknown", "unknown", 
                    ifelse (job == "student" | 
                      job == "retired" | job == "unemployed", "no", "yes")),
         Age_Blocks = ifelse(age>60 | age == 60, "60+", 
                             ifelse(age < 60 & age > 50, "50-60", 
                             ifelse(age < 51 & age > 29, "30-50",
                                    ifelse(age < 30, "0-30", "unknown")))),
         ActiveMonths = ifelse(month == "mar", "high", 
                      ifelse(month == "nov" | month == "jun" | month == "may", "med", "low")))



#Show DV for these features
subsidyRevised %>%
    dplyr::select(y, Employed, Age_Blocks, ActiveMonths) %>%
    gather(Variable, value, -y) %>%
    count(Variable, value, y)%>%
  mutate(rate = lag(n)/n)%>%
    filter(y=="no")%>%
      ggplot(., aes(value, rate)) +   
        geom_bar(position = "dodge", stat="identity") +
        facet_wrap(~Variable, scales="free") +
        labs(x="Category", y="Percentage of 'Yes' Results",
             title = "Modified Features",
             subtitle = "Categorical features") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))



```

## Regression Summary

Using these new variables and selecting from a group of those with low p-values and high significance, we split a new data partition and train a revised model. See below that these values have much more focused significance. 

```{r Revised Model, warning = FALSE, message = FALSE}

set.seed(999)
trainIndexRevised <- createDataPartition(subsidyRevised$y, p = .65,
                                  list = FALSE,
                                  times = 1)
subsidyTrainRev <- subsidyRevised[ trainIndex,]
subsidyTestRev  <- subsidyRevised[-trainIndex,]

#Make new regression for engineered model
subsidyModelRev <- glm(y_numeric ~ .,
                  data=subsidyTrainRev %>% 
                    dplyr::select(y_numeric, Repairs_4800up, campaign, ActiveMonths, poutcome, contact, cons.price.idx, cons.conf.idx,unemploy_rate, Age_Blocks, mortgage),
                  family="binomial" (link="logit"))

#Compare new and old models
summary(subsidyModelRev)

```

However, it proved difficult to increase the McFadden R-squared metric. This may be due to blind spots in the data or noise that I haven't removed. No other variables appeared to substantailly increase this value on their own, so I chose to leave this metric and move forward with the forecast knowing that this revised model had similar performance with a more efficient set of variables.

```{r McFadden R-Squared Comparison, warning = FALSE, message = FALSE}

tidy(pR2(subsidyModelRev))%>%
mutate(Regression = "Engineered")%>%
rbind(regSubsidySummary)%>%
filter(names == "McFadden")%>%
dplyr::select(-names)%>%
rename(McFadden_R2 = x)%>%
  kable(
  caption = "<strong></strong>",
  escape= FALSE,
  format="html",
  row.names = FALSE,
  align="l")%>%
kable_styling()
```



## CV + Comparison

These cross-validation results below illustrate the same inability to replicate a goodness of fit while using less variables. The sensitivity, or ratio of true positive values to all positive values, was quite similar in results between these two models. The revised model has a worse fit of results to the ROC metric, with more of the predictions skewing toward 1. 

```{r Kitchen Sink Model CV, warning = FALSE, message = FALSE}

#ROC, Sensitivity, Specificity
ctrl <- trainControl(method = "cv", number = 100, classProbs=TRUE, summaryFunction=twoClassSummary)

cvFit <- train(y ~ .,
                  data=subsidy %>% 
                    dplyr::select(-y_numeric), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)

cvFit


#Goodness of Fit Metrics
dplyr::select(cvFit$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics, Kitchen Sink Model",
         subtitle = "Across-fold mean reprented as dotted lines")

```



```{r Revised Cross Validation, warning = FALSE, message = FALSE}

#ROC, Sensitivity, Specificity
cvFitRevised <- train(y ~ .,
                  data=subsidyRevised %>% 
                    dplyr::select(y, Repairs_4800up, unemploy_rate, campaign, ActiveMonths, poutcome, contact, cons.price.idx, cons.conf.idx, Age_Blocks, mortgage), 
                method="glm", family="binomial",
                metric="ROC", trControl = ctrl)

cvFitRevised


#Goodness of Fit Metrics
dplyr::select(cvFitRevised$resample, -Resample) %>%
  gather(metric, value) %>%
  left_join(gather(cvFit$results[2:4], metric, mean)) %>%
  ggplot(aes(value)) + 
    geom_histogram(bins=35, fill = "#FF006A") +
    facet_wrap(~metric) +
    geom_vline(aes(xintercept = mean), colour = "#981FAC", linetype = 3, size = 1.5) +
    scale_x_continuous(limits = c(0, 1)) +
    labs(x="Goodness of Fit", y="Count", title="CV Goodness of Fit Metrics, Engineered Model",
         subtitle = "Across-fold mean reprented as dotted lines")

```

# Usefulness of New Model (ROC)

Output an ROC curve for your new model and interpret it.

```{r ROC Metrics, warning = FALSE, message = FALSE}

testProbs <- data.frame(Outcome = as.factor(subsidyTestRev$y_numeric),
                        Probs = predict(subsidyModelRev, subsidyTestRev, type= "response"))

testProbs <- 
  testProbs %>%
  mutate(predOutcome  = as.factor(ifelse(testProbs$Probs > 0.5 , 1, 0)))

caret::confusionMatrix(testProbs$predOutcome, testProbs$Outcome, 
                       positive = "1")

auc(testProbs$Outcome, testProbs$Probs)

```

```{r ROC Curve, warning = FALSE, message = FALSE}
ggplot(testProbs, aes(d = as.numeric(Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - subsidyModelRev")
```

# Cost Benefit Analysis

Develop a cost benefit analysis.

## Equations

Write out the cost/benefit equation for each confusion metric.

**True Positive Revenue** "We predicted the citizen would participate in the subsidy program once marketed to (\$2850 cost), and they did. 25% of participants complete program process and receive the subsidy of \$5000. They and their neighbors benefit from increased housing value (\$10,000 and \$56,000 respectively), and the city captures that annually in property taxes (1.4%) and sales taxes (3.3%). We assume 6% of these homes are sold annually. Repairs are estimated to last 10+ years on average, so annual benefit is applied for 10 years as a conservative estimate."

-\$2850 marketing + 0.25 successes \* (-\$5000 subsidy + ((\$10,000 + \$56,000)\*0.014 annual property tax + ((\$10,000 + \$56,000)\*0.06 home sales \*0.033 real estate transfer tax))\* 10 years).

**True Negative Revenue** "We predicted citizen would not participate in the credit program, did not allocate marketing resources toward them. Citizen did not participate in the program, no credit allocated."

\$0

**False Positive Revenue** "We predicted citizen would participate in credit program, allocated marketing resources toward them (\$2850 cost). citizen did not participate the credit program."

-\$2850

**False Negative Revenue** "Predicted citizen would not participate in the credit program, did not allocate marketing resources. Citizen participated in the program no cost to the campaign."

\$0


## Table of Costs and Benefits

Create the 'Cost/Benefit Table' as seen above.

-\$2850 marketing + 0.25 successes \* (-\$5000 subsidy + ((\$10,000 + \$56,000)\*0.014 annual property tax + ((\$10,000 + \$56,000)\*0.06 home sales \*0.033 real estate transfer tax))\* 10 years).

```{r Cost Benefit Table, warning = FALSE, message = FALSE}

cost_benefit_table <-
   testProbs %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
       gather(Variable, Count) %>%
       mutate(Revenue =
               ifelse(Variable == "True_Negative", Count * 0,
               ifelse(Variable == "True_Positive",(
                 (-2850 + #marketing cost
                  0.25*(-5000 #successful participation and subsidy 
                 +((10000+56000)*0.02 #property tax
                 +(10000+56000)*0.10*0.05) #real estate transfer tax
                 *15)) #applied over 15 years
                 * Count),
               ifelse(Variable == "False_Negative", Count * 0,
               ifelse(Variable == "False_Positive", (-2850) * Count, 0))))) %>%
    bind_cols(data.frame(Description = c(
              "We correctly predicted no participation",
              "We correctly predicted participation, with 25% receiving subsidy",
              "We predicted no particiption and the citizen pariticpated",
              "We predicted particiption and citizen did not participate")))

kable(cost_benefit_table,
       caption = "Cost/Benefit Table") %>% kable_styling()


```

## Confusion Metrics

Plot the confusion metric outcomes for each Threshold.

```{r Thresholds for Each Confusion Metric, warning = FALSE, message = FALSE}

iterateThresholds <- function(data) {
  x = .01
  all_prediction <- data.frame()
  while (x <= 1) {
  
  this_prediction <-
      testProbs %>%
      mutate(predOutcome = ifelse(Probs > x, 1, 0)) %>%
      count(predOutcome, Outcome) %>%
      summarize(True_Negative = sum(n[predOutcome==0 & Outcome==0]),
                True_Positive = sum(n[predOutcome==1 & Outcome==1]),
                False_Negative = sum(n[predOutcome==0 & Outcome==1]),
                False_Positive = sum(n[predOutcome==1 & Outcome==0])) %>%
     gather(Variable, Count) %>%
     mutate(Revenue =
               ifelse(Variable == "True_Negative", Count * 0,
               ifelse(Variable == "True_Positive",((-2850  
                                                  + 0.25*(-5000 
                                                  + ((10000+56000)*0.02 
                                                  + (10000+56000)*0.10*0.04)
                                                  *15))
                                                  * Count),
               ifelse(Variable == "False_Negative", (0) * Count,
               ifelse(Variable == "False_Positive", (-2850) * Count, 0)))),
            Threshold = x)
  
  all_prediction <- rbind(all_prediction, this_prediction)
  x <- x + .01
  }
return(all_prediction)
}

whichThreshold <- iterateThresholds(testProbs2)

#Revenue Confusion Matrix Plot
revThresholdPlot <- whichThreshold %>%
  ggplot(.,aes(Threshold, Revenue, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "Threshold as a Function of Revenue",
       y = "Threshold") +
  plotTheme() +
  guides(colour=guide_legend(title = "Confusion Matrix"))

#Count of Subsidies Confusion Matrix Plot
countThresholdPlot <- whichThreshold %>%
  ggplot(.,aes(Threshold, Count, colour = Variable)) +
  geom_point() +
  scale_colour_manual(values = palette5[c(5, 1:3)]) +    
  labs(title = "Threshold as a function of Total Counts",
       y = "Threshold") +
  plotTheme() +
  guides(colour=guide_legend(title = "Confusion Matrix"))

grid.arrange(revThresholdPlot, countThresholdPlot, nrow=2)

```

## Total Revenuse and Count of Credits

Create two small multiple plots that show Threshold as a function of Total_Revenue and Total_Count_of_Credits. Interpret this.

The two plots below help us determine which threshold maximizes the city's revenue and which maximizes the total amount of citizens receiving the credit.

```{r Optimal Thresholds , warning = FALSE, message = FALSE}

whichThreshold_revenue <- 
whichThreshold %>% 
    group_by(Threshold) %>% 
    summarize(Revenue = sum(Revenue))%>%
    round(digits=2)

revOptimalPlot <-
  ggplot(whichThreshold_revenue)+
geom_line(aes(x = Threshold, y = Revenue))+
geom_vline(xintercept =  pull(arrange(whichThreshold_revenue, -Revenue)[1,1]))+
  labs(title = "Net Revenue by Threshold",
       subtitle = "Vertical Line Denotes Optimal Threshold")

whichThreshold_counts <- 
    whichThreshold%>% 
    group_by(Threshold)%>%
    mutate(TotalCount = ifelse(Variable == "True_Negative", 0,
                     ifelse(Variable == "True_Positive", Count,
               ifelse(Variable == "False_Negative", 0,
               ifelse(Variable == "False_Positive", Count * -1, 0)))))%>%
    summarize(TotalCount = sum(TotalCount))%>%
  round(digits=2)
  
Optimal_Threshold <- pull(arrange(whichThreshold_counts, -TotalCount)[1,1])

countOptimalPlot <-
    ggplot(whichThreshold_counts)+
geom_line(aes(x = Threshold, y = TotalCount))+
geom_vline(xintercept =  pull(arrange(whichThreshold_counts, -TotalCount)[1,1]))+
  labs(title = "Net Participants by Threshold",
       subtitle = "Vertical Line Denotes Optimal Threshold",
       y= "Total Count (TP - FP)")

grid.arrange(countOptimalPlot, revOptimalPlot, ncol=2)


```

## Optimal Thresholds

Create a table of the Total_Revenue and Total_Count_of_Credits allocated for 2 categories. 50%\_Threshold and your Optimal_Threshold.

```{r 0.50 and Optimal Threshold Measures, warning = FALSE, message = FALSE}

whichThreshold_Summary <-
  whichThreshold_counts %>%
  left_join(whichThreshold_revenue, by="Threshold")%>%
  filter(Threshold == 0.50 | Threshold == Optimal_Threshold)

whichThreshold_Summary%>%
  kable(
    caption = "<strong></strong>",
    escape= FALSE,
    format="html",
    row.names = FALSE,
    align="l")%>%
  kable_styling()

```

# Conclusion

Conclude whether and why this model should or shouldn't be put into production. What could make the model better? What would you do to ensure that the marketing materials resulted in a better response rate?
